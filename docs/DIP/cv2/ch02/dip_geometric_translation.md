# **Geometric Transformations of Images**

## **Goals**

- Learn to apply different ***geometric transformation*** to images like
    - translation,
    - rotation,
    - affine transformation etc.
- You will see these functions:Â `cv2.getPerspectiveTransform`

# **Transformations**

> ***[Transformation](https://www.notion.so/1-8-Introduction-to-Linear-Transformations-61b0a5ff0bc747b6ba1ef9aca6168fac)***ì´ë€?
> 
> 
> The **function** to convert(map) an specific coordinateÂ $\textbf{x}$Â into other coordinate systemÂ $\textbf{x}^\prime$.
> 
>  [Basis](https://www.notion.so/4-3-Linearly-Independent-Sets-Bases-13c20d906e314ed5b920b7095c038075) ë¥¼ ë°”ê¾¸ëŠ” ê²ƒì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŒ.
> 

# Pre-requirements

 ë‹¤ìŒ ë¬¸ì„œëŠ” ì˜ìƒì²˜ë¦¬ì˜ ê¸°í•˜í•™ì  ë³€í™˜ì˜ ê¸°ë³¸ì´ ë˜ëŠ” ì„ í˜•ëŒ€ìˆ˜ ë‚´ìš©ì´ ê°„ëµíˆ ì„¤ëª…ë¨.

[2.7 Applications to Computer Graphics](https://www.notion.so/2-7-Applications-to-Computer-Graphics-9b52d9335a344cb88ccddf1a97063d4f)

[1.8 Introduction to Linear Transformations](https://www.notion.so/1-8-Introduction-to-Linear-Transformations-61b0a5ff0bc747b6ba1ef9aca6168fac)

# 2D Geometric Image Transformations

![[Computer Vision - Algorithms and Applications](https://www.semanticscholar.org/paper/Computer-Vision-Algorithms-and-Applications-Szeliski/4282a344671189e17c9c9e00e329fe2d0fa71769/figure/263)](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e6d66e69-ef26-4ef3-9618-f47c4e4508dd/Untitled.png)

[Computer Vision - Algorithms and Applications](https://www.semanticscholar.org/paper/Computer-Vision-Algorithms-and-Applications-Szeliski/4282a344671189e17c9c9e00e329fe2d0fa71769/figure/263)

- **Rigid-body(ê°•ì²´)**Â transformation :
    - ***shape(í˜•íƒœ),*** ***size(í¬ê¸°)*** and ***angle(ê°)*** are preserved.
        - DoF : 3 â†’ 2ìŒ ì´ìƒì˜ matchë˜ëŠ” ì (=4ê°œì˜ ê°’ìœ¼ë¡œ ê°¯ìˆ˜ê°€ 3ë³´ë‹¤ í¬ë‹ˆ ì¶©ë¶„í•¨)ì´ í•„ìš”.
    - i.e.,
        - **Translation**,
        - **Rotation**, and
        - **Identity**
    - It is called **Euclidean** transformation.
        
        $$
        \begin{bmatrix} x^\prime \\ y^\prime \end{bmatrix}=\begin{bmatrix} \cos \theta & -\sin\theta  \\ \sin\theta & \cos\theta  \end{bmatrix}\begin{bmatrix} x \\ y \end{bmatrix}+ \begin{bmatrix} c \\ d \end{bmatrix}\\\begin{bmatrix} x^\prime \\ y^\prime \\1\end{bmatrix}=\begin{bmatrix} \cos \theta & -\sin\theta &c \\ \sin\theta & \cos\theta &d \\0 & 0 & 1\end{bmatrix}\begin{bmatrix} x \\ y \\1\end{bmatrix}
        $$
        
    - `cv2.estimateRigidTransform()` ì„ í†µí•´ 2ìŒ ì´ìƒì˜ matchë˜ëŠ” ì ë“¤ë¡œë¶€í„° ë³€í™˜ matrixë¥¼ êµ¬í•¨. (ì‹¤ì œë¡  affine transform matrixë¥¼ êµ¬í•´ì¤Œ) â† [detail](https://docs.opencv.org/2.4.13.2/modules/video/doc/motion_analysis_and_object_tracking.html#estimaterigidtransform)
    
- **Similarity** transformation (or similitudes, ìœ ì‚¬ë³€í™˜, ë‹®ì€ë³€í™˜) :
    - **Rigid-body** transformation + (Isotropic) **Scaling**
        - DoF : 4 (íšŒì „ê°, x,yì¶•ì˜ translation, scaling factor)
        - 2ìŒ ì´ìƒì˜ matchë˜ëŠ” ì ì´ ìˆì–´ì•¼ íŒŒë¼ë©”í„° êµ¬í•  ìˆ˜ ìˆìŒ.
    - ***angle*** is preserved but
    - ***size** can be changed*. (í™•ëŒ€/ì¶•ì†Œ ë•Œë¬¸ì—)
    - i.e.,
        - **(Isotropic) Scaling**
    - `cv2.estimateRigidTransform()` ì„ í†µí•´ 2ìŒ ì´ìƒì˜ matchë˜ëŠ” ì ë“¤ë¡œë¶€í„° ë³€í™˜ matrixë¥¼ êµ¬í•¨. (ì‹¤ì œë¡  affine transform matrixë¥¼ êµ¬í•´ì¤Œ) â† [detail](https://docs.opencv.org/2.4.13.2/modules/video/doc/motion_analysis_and_object_tracking.html#estimaterigidtransform)
- **[Linear** transformation](https://www.notion.so/1-8-Introduction-to-Linear-Transformations-61b0a5ff0bc747b6ba1ef9aca6168fac) :
    - *Function* to mapping on the vector space.
    - It specifies
        - **homogeniety**Â and
        - **additivity**.
    - i.e.,
        - **Scaling (isotropic scaling í¬í•¨)**,
        - **Shear**,
        - **Reflection**, and
        - **Rotation about the origin.**
    
    > Translation(ì´ë™)ì€ Homogeniety(ë™ì°¨ì„±)ì„ ë§Œì¡±í•˜ì§€ ëª»í•¨ â†’ linear transformationì´ ì•„ë‹˜. â† Homogeneous coordinateì‚¬ìš©ì‹œ linearityë¥¼ ê°€ì§€ê²Œ ë˜ì–´ matrixê³±ë§Œìœ¼ë¡œ ì²˜ë¦¬ ê°€ëŠ¥í•´ì§.
    > 
- **Affine**Â transformation :
    - Linear transformation + **Translation**.
        - DoF : 6
        - 3ìŒì˜ matchë˜ëŠ” ì ë“¤ì´ ìˆì–´ì•¼ standard matrixë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŒ.
        
        $$
        \begin{bmatrix} x^\prime \\ y^\prime \\1\end{bmatrix}=\begin{bmatrix} a & b &e \\ c & d &f\\0 & 0 & 1\end{bmatrix}\begin{bmatrix} x \\ y \\1\end{bmatrix}
        $$
        
        â† OpenCvì—ì„œëŠ” $2 \times 3$ matrixë¡œ ì²˜ë¦¬ë¨.
        
    - Function between affine spaces which preserves **points**, **straight lines** and **planes**.
    - ì„ ë“¤ì˜ í‰í–‰ì„±ì´ ë³´ì¥ëœë‹¤. â†’ ***ì„ì˜ì˜ í‰ë©´ì´ ì„ì˜ì˜ í‰ë©´***ìœ¼ë¡œ ***í‰í–‰ì„±ì„ ë³´ì¡´***í•˜ë©´ì„œ ë§¤í•‘ë¨.
        - ì°¸ê³ 
            
            ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/708c2e7e-68c1-441c-bd78-9227fe81005a/Untitled.png)
            
    - `cv2.getAffineTransform()` ì„ í†µí•´ 3ìŒì˜ matchë˜ëŠ” ì ì„ í†µí•´ ë³€í™˜matrixë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ.
    `cv2.invertAffineTransform()` ë¥¼ í†µí•´ inverse matrixë„ êµ¬í•  ìˆ˜ ìˆìŒ.
- **Perspective**Â transformation (ì›ê·¼ë³€í™˜) :
    - Affine transformation w/o the property to keep parallel lines.
        - ì„ ì€ ë³€í™˜ í›„ì—ë„ ì„ ìœ¼ë¡œ ìœ ì§€ë¨.
        - ë‹¨, ì„ ì˜ í‰í–‰ì„±ì€ ìœ ì§€ê°€ ë³´ì¥ë˜ì§€ ì•ŠìŒ.
        - ì„ì˜ì˜ í‰ë©´ì´ ì„ì˜ì˜ í‰ë©´ìœ¼ë¡œ í‰í–‰ì„±ì„ ë³´ì¡´í•˜ì§€ ì•Šê³  ë§¤í•‘ë¨.
    - 3D ê³µê°„ì˜ ì…ì²´ì ì¸ ë¬¼ì²´ë¥¼ í‰ë©´ì— íˆ¬ì˜í•˜ëŠ”ë° ì‚¬ìš©ë˜ë©° ì›ê·¼ê°ì´ í‘œí˜„ë¨.
        - DoF : 8 ($3\times 3$ matrixì´ë‚˜ homogeneous coordinateì—ì„œ ë§ˆì§€ë§‰ componentê°€ 1ë¡œ ê³ ì •ì´ë‚˜ ë‹¤ë¦„ì´ ì—†ê¸° ë•Œë¬¸ì—, matrixì˜ 3í–‰ 3ì—´ì˜ entryê°€ 1ì´ë¼ëŠ” constant valueì„ ê°€ì§€ê²Œ ë˜ì–´ 9-1ë¡œ 8 DoFë¥¼ ê°€ì§.)
    - Perspective projection, Projective transformation, Homograpy ë¼ê³ ë„ ë¶ˆë¦¼.
        
        <aside>
        ğŸ’¡ Homographyë¥¼ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•œ í•œ ì¢‹ì€ ë°©ë²•
        
        - 2D í‰ë©´ì—ì„œ ì„ì˜ì˜ ì‚¬ê°í˜•ì„ ì„ì˜ì˜ ì‚¬ê°í˜•ìœ¼ë¡œ ë§¤í•‘ì‹œí‚¬ ìˆ˜ ìˆëŠ” ë³€í™˜ì´ homography ë¼ê³  ìƒê°í•  ì„œ.
        - ì–´ë–¤ planer surface ì´¬ì˜ëŒ€ìƒì´ ì„œë¡œ ë‹¤ë¥¸ ìœ„ì¹˜ì˜ ì¹´ë©”ë¼ë¡œ ì´¬ì˜ë˜ì–´ image A, image Bë¡œ íˆ¬ì˜ëœ ê²½ìš°, ì´ Aì™€ Bì‚¬ì´ì˜ ì ë“¤ì˜ ìœ„ì¹˜ ê´€ê³„ë¥¼ homographyë¡œ í‘œí˜„ê°€ëŠ¥í•¨.
        - í‰ë©´ë¬¼ì²´ì˜ 2D ì´ë¯¸ì§€ ë³€í™˜ê´€ê³„ë¥¼ ì„¤ëª…í•¨.
        - Projective transformationê³¼ homographyëŠ” ê°™ì€ ë§ì„.
        </aside>
        
    - `cv2.getPerspectiveTransform()` ë¥¼ í†µí•´ *4ìŒì˜ matchë˜ëŠ” ì *ìœ¼ë¡œë¶€í„° ë³€í™˜í–‰ë ¬ êµ¬í•´ì¤Œ.
    `cv2.findHomography()`ëŠ” *4ìŒ ì´ìƒì˜ matchë˜ëŠ” ì *ë“¤ë¶€í„° ë³€í™˜í–‰ë ¬ì„ êµ¬í•´ì¤Œ(approximate methodë¡œ , fitting, RANSAC, LMedSì¤‘ ì„ íƒê°€ëŠ¥)

---

# Geometric Transformation in the OpenCV

`OpenCV`Â providesÂ twoÂ geometric transformationÂ functions,

- `cv2.warpAffine`Â and
- `cv2.warpPerspective`,

withÂ whichÂ youÂ canÂ haveÂ allÂ kindsÂ ofÂ geometric transformations.

- Note:Â **Warping**Â Transformation
    - êµ´ê³¡Â ë³€í™˜
    - ë¹„ì„ í˜•ì Â ê¸°í•˜í•™ì Â ì—°ì‚°

## Affine Transformation vs. Perspective Transformation

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/43155a34-6592-48e4-b022-8dcfb3a7f65c/Untitled.png)

`cv2.warpAffine` takes 

- a $2\times3$ transformation matrix (6DOFs)

while `cv2.warpPerspective` takes 

- a $3\times3$ transformation matrix (8DOFs) as input.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4f5ad718-3376-44a5-9a62-7718dbad3f1c/Untitled.png)

- Affine Transformationì—ì„œ 6ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì•Œê¸° ìœ„í•´ì„œëŠ” 6ê°œì˜ ì—°ë¦½ ë°©ì •ì‹ì´ í•„ìš”.
    - 1ê°œì˜ (x, y)ì— ëŒ€í•œ homogeneous í–‰ë ¬ì—ì„œ DOFì— ê´€í•œ 2ê°œì˜ ì‹ì„ êµ¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— 3ê°œ ì ì˜ 6ê°œ ì‹ì„ ì´ìš©í•˜ë©´ 6ê°œì˜ DOFë¥¼ êµ¬í•  ìˆ˜ ìˆìŒ.
    - ì´ëŠ” ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ Affine Transformationì´ í‰í–‰ì‚¬ë³€í˜• í˜•íƒœë¥¼ ìœ ì§€í•˜ëŠ” ë³€í™˜ì´ê¸° ë•Œë¬¸ì— 3ê°œì˜ ì ì„ ì§€ì •í•˜ë©´ ìë™ì ìœ¼ë¡œ í•˜ë‚˜ì˜ ì ì´ ê³ ì •ì´ ë˜ì–´ 3ê°œì˜ ì ì„ í†µí•´ ë³€í™˜ í–‰ë ¬ì„ êµ¬í•  ìˆ˜ ìˆëŠ” ê²ƒê³¼ ê°™ì€ ì˜ë¯¸ì„.
    - **3ê°œì˜ ì ì˜ ë³€í™˜ ì „ ì¢Œí‘œì™€ ë³€í™˜ í›„ ì¢Œí‘œë¥¼ ì•Œì•„ì•¼ Affine ë³€í™˜ í–‰ë ¬ì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**
- ì´ì™€ ë™ì¼í•œ ê´€ì ì—ì„œ Perspective Transformationì€ 8ê°œì˜ DOFë¥¼ êµ¬í•˜ê¸° ìœ„í•˜ì—¬ 4ê°œì˜ ì ì„ ì‚¬ìš©í•˜ì—¬ êµ¬í•  ìˆ˜ ìˆìŒ.
    - ì´ëŠ” ìœ„ ê·¸ë¦¼ê³¼ ê°™ì´ Perspective Transformationì—ì„œëŠ” 4ê°œì˜ ê¼­ì§€ì ì´ ììœ ë¡­ê²Œ ë³€í™˜ëœ ìƒíƒœë¡œ ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•  ìˆ˜ ìˆì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì—Â **4ê°œì˜ ì ì˜ ë³€í™˜ ì „ ì¢Œí‘œì™€ ë³€í™˜ í›„ ì¢Œí‘œë¥¼ ì•Œì•„ì•¼ Perspective ë³€í™˜ í–‰ë ¬ì„ êµ¬í•  ìˆ˜**Â ìˆìŒ.

---

# Translation

> TranslationÂ isÂ theÂ shiftingÂ ofÂ objectâ€™sÂ location.
> 

IfÂ youÂ knowÂ theÂ shiftÂ inÂ $(x,y)$-direction,Â 
letÂ itÂ beÂ $(t_x,t_y)$,Â youÂ canÂ createÂ theÂ transformationÂ matrixÂ $\textbf{M}$Â asÂ follows:

$$
MÂ =Â \begin{bmatrix}
1Â &Â 0Â &Â t_xÂ \\
0Â &Â 1Â &Â t_y
\end{bmatrix}
$$

YouÂ canÂ 

- make itÂ intoÂ aÂ **NumpyÂ arrayÂ ofÂ type**Â `np.float32`Â and
- passÂ itÂ intoÂ `cv2.warpAffine()`Â function.

SeeÂ belowÂ exampleÂ forÂ aÂ shiftÂ ofÂ `(150,50)`:

- python code
    
    ```python
    from skimage import data
    from skimage import img_as_ubyte,img_as_float
    import cv2
    import numpy as np
    import matplotlib.pyplot as plt
    
    cat = data.chelsea() # take the test image of cat!
    img = cv2.cvtColor(cat, cv2.COLOR_RGB2GRAY)
    # img = cv2.imread('cat_cv.tif',0)
    
    rows,cols = img.shape
    
    M = np.float32([[1,0,150],
                    [0,1,50]])
    
    dst = cv2.warpAffine(img,M,(cols,rows))
    
    # cv2.imshow('img',dst)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    plt.figure(figsize=(12,12))
    plt.subplot(121); plt.imshow(img, cmap='gray'), plt.axis('off')
    plt.subplot(122); plt.imshow(dst, cmap='gray'), plt.axis('off')
    plt.show()
    ```
    
- Result
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fc055368-7910-4a17-a4ea-8ec312dd0a52/Untitled.png)
    

# Rotation

RotationÂ ofÂ anÂ imageÂ forÂ anÂ angleÂ $\theta$Â canÂ alsoÂ beÂ doneÂ usingÂ `wrapAffine()` â€”onlyÂ theÂ transformationÂ matrixÂ changes.

TheÂ transformationÂ matrixÂ forÂ theÂ rotationÂ isÂ asÂ follows:

$$
M = \begin{bmatrix}
\cos\theta & -\sin\theta \\
\sin\theta & \cos\theta
\end{bmatrix}
$$

- **ê¼¬ë§ˆ**ê°€ **ì‹  ì‹ ê³ **

ButÂ OpenCVÂ providesÂ **scaledÂ rotation**Â withÂ **adjustableÂ centerÂ ofÂ rotation**Â soÂ thatÂ youÂ canÂ rotateÂ atÂ anyÂ locationÂ youÂ prefer.

ModifiedÂ transformationÂ matrixÂ isÂ givenÂ by

$$
\begin{bmatrix}
\alpha &  \beta & (1- \alpha )  \cdot \text{center.x} - \beta \cdot \text{center.y} \\

-\beta & \alpha & \beta \cdot \text{center.x} + (1- \alpha ) \cdot \text{center.y}

\end{bmatrix}
$$

where:

$$
\begin{array}{l}
\alpha =  \text{scale} \cdot \cos \theta , \\
\beta =  \text{scale}\cdot \sin \theta
\end{array}
$$

ToÂ findÂ thisÂ transformationÂ matrix,Â OpenCVÂ providesÂ aÂ function,Â `cv2.getRotationMatrix2D`.
ItÂ takesÂ 

- theÂ centerÂ forÂ rotation (â†pixel),
- angleÂ ofÂ rotation (â†degree),Â and
- isotropic scalingÂ factorÂ asÂ input.
- Ref. API for `getRotationMatrix2D`
    
    [OpenCV: Geometric Image Transformations](https://docs.opencv.org/3.4.0/da/d54/group__imgproc__transform.html#gafbbc470ce83812914a70abfb604f4326)
    

CheckÂ belowÂ exampleÂ whichÂ rotatesÂ theÂ imageÂ byÂ 30Â degreeÂ withÂ respectÂ toÂ centerÂ withoutÂ anyÂ scaling.

- python code
    
    ```python
    from skimage import data
    from skimage import img_as_ubyte,img_as_float
    import cv2
    import numpy as np
    import matplotlib.pyplot as plt
    
    cat = data.chelsea() # take the test image of cat!
    img = cv2.cvtColor(cat, cv2.COLOR_RGB2GRAY)
    #img = cv2.imread('cat_cv.tif',0)
    
    rows,cols = img.shape # there is no channel
    
    #------------------------------------
    # getRotationMatrix2D
    # the rotation center is given by Tupple.
    # (center.x cneter.y), rotation degree, scale
    M = cv2.getRotationMatrix2D((cols/2,rows/2),30,1)
    print(M)
    
    dst = cv2.warpAffine(img,M,(cols,rows))
    
    # cv2.imshow('img',dst)
    # cv2.waitKey(0)
    # cv2.destroyAllWindows()
    
    plt.figure(figsize=(12,12))
    plt.subplot(121); plt.imshow(img, cmap='gray'), plt.axis('off')
    plt.subplot(122); plt.imshow(dst, cmap='gray'), plt.axis('off')
    plt.show()
    ```
    
- result
    
    [[  0.8660254    0.5        -44.78872855]
     [ -0.5          0.8660254  132.84618943]]
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1cc0d5d0-7009-4988-86c2-5cfa21c327aa/Untitled.png)
    

---

# Scaling

***Scaling***Â isÂ justÂ **resizing**Â ofÂ theÂ image.

OpenCVÂ comesÂ withÂ aÂ functionÂ `cv2.resize()`Â forÂ thisÂ purpose.

**`cv2.resize(img,Â dsize,Â fx,Â fy,Â interpolation)`**

- `img`Â :Â sourceÂ image
- `dsize`Â :Â desiredÂ sizeÂ (specifiedÂ manually),Â `tupleÂ (width,height)`
- `fx`Â :Â scaleÂ factorÂ alongÂ theÂ horizontalÂ axis
- `fy`Â :Â scaleÂ factorÂ alongÂ theÂ verticalÂ axis
- `interpolation` : the method of interpolation

TheÂ **size**Â ofÂ theÂ imageÂ canÂ beÂ specifiedÂ manually,Â orÂ youÂ canÂ specifyÂ **theÂ scalingÂ factor**.

DifferentÂ ***interpolationÂ method**s*Â areÂ used.

- PreferableÂ interpolationÂ methodsÂ areÂ `cv2.INTER_AREA`Â forÂ **shrinking**Â and
- `cv2.INTER_CUBIC`Â (slow)Â &Â `cv2.INTER_LINEAR`Â forÂ **zooming**.

ByÂ default,Â interpolationÂ methodÂ usedÂ isÂ `cv2.INTER_LINEAR`Â forÂ allÂ resizingÂ purposes.

VariousÂ interpolationÂ algorithmsÂ areÂ providedÂ byÂ OpenCvÂ asÂ follows;

- `cv2.INTER_AREA`
    - ItÂ isÂ preferredÂ forÂ shrinkingÂ theÂ imageÂ size.
- `cv2.INTER_LINEAR`
    - defaultÂ algorithm.
    - ItÂ isÂ commonlyÂ usedÂ forÂ zooming.
- `cv2.INTER_CUBIC`
    - ItÂ isÂ usedÂ forÂ zoomingÂ withÂ aÂ betterÂ qualityÂ butÂ slow.
- `cv2.INTER_NEAREST`
    - VeryÂ fastÂ butÂ qualityÂ isÂ notÂ good.

YouÂ canÂ resizeÂ anÂ inputÂ imageÂ eitherÂ ofÂ above methods:

- python code
    
    ```python
    from skimage import data
    from skimage import img_as_ubyte,img_as_float
    import cv2
    import numpy as np
    import matplotlib.pyplot as plt
    
    #img = cv2.imread('cat_cv.tif')
    
    height, width = img.shape[:2]
    print("original dimension : ({}, {}, {})".format(height,width,channel))
    
    #-------------------
    zoomed_cat = cv2.resize(img,None,fx=2, fy=2, interpolation = cv2.INTER_CUBIC)
    #OR
    zoomed_cat = cv2.resize(img,(2*width, 2*height), interpolation = cv2.INTER_CUBIC)
    #-------------------
    
    print("modified dimension :",zoomed_cat.shape)
    cv2.imshow('zoomed_cat',zoomed_cat)
    # cv2_imshow(zoomed_cat)
    
    zoomed_cat_NN = cv2.resize(img, (2*width,2*height), interpolation = cv2.INTER_NEAREST)
    cv2.imshow('zoomed_cat_NN',zoomed_cat_NN)
    #cv2_imshow(zoomed_cat_NN)
    
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    ```
    
- result
    
    original dimension : (300, 451, 3)
    modified dimension : (600, 902)
    

# Review : Cropping

In `OpenCv`, cropping is provided by using the `slicing` of python. 

Slicing an array is just taking the array values within particular index range.

- python code
    
    ```python
    import matplotlib.pyplot as plt
    
    zoomed_cat = cv2.cvtColor(zoomed_cat,cv2.COLOR_RGB2BGR)
    zoomed_cat_NN = cv2.cvtColor(zoomed_cat_NN,cv2.COLOR_RGB2BGR)
    
    cropped_img0 = zoomed_cat[150:300,250:450]
    #cv2_imshow(cropped_img0)
    cropped_img1 = zoomed_cat_NN[150:300,250:450]
    #cv2_imshow(cropped_img1)
    
    plt.figure(figsize=(12,12))
    plt.subplot(121); plt.imshow(cropped_img0) # expects distored color
    plt.subplot(122); plt.imshow(cropped_img1) # expects true color
    plt.show()
    
    #--------------------------------------
    # be careful to modify the cropped img.
    tmp = cropped_img0.copy()
    cropped_img0[:]=0
    
    #cv2_imshow(zoomed_cat)
    #cv2_imshow(tmp)
    plt.imshow(zoomed_cat)
    plt.show()
    plt.imshow(tmp)
    plt.show()
    
    zoomed_cat[150:300,250:450]=tmp
    #cv2_imshow(zoomed_cat)
    plt.imshow(zoomed_cat)
    plt.show()
    ```
    
- result
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f9d7a10b-55ee-4a19-81b3-ae4613bf3ef9/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f9550207-db9e-4092-b7c5-81e8cfb1159d/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c68a7de2-f257-446e-9fbc-18f06695cc79/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/52d08d87-0683-43fb-9976-d8a780aacbc7/Untitled.png)
    

---

# Reflection (Flip) Transformation (ëŒ€ì¹­ë³€í™˜)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fa0cf512-f989-4191-80c7-0c5d29d9eeca/Untitled.png)

- Reflection + Translation = flip
- Linear Transformation : [Reflections](https://www.notion.so/6dd79c1d2b27428a804825845377529d)

`cv2.flip(src, flipMode, dst = None) -> dst`

- `src` : input image
- `flipMode` : +1 (ì¢Œìš°), 0 (ìƒí•˜), -1 (ì›ì )
- `dst` : output image

---

# Affine Transformation

In affine transformation, **all parallel lines** in the original image will still be **parallel** in the output image.

To find the transformation matrix, we needÂ ***three points***Â from input image and their corresponding locations in output image.

ThenÂ `cv2.getAffineTransform`Â will create a $2\times3$ matrix which is to be passed toÂ `cv2.warpAffine`.

Check below example, and also look at the points I selected (which are marked in Green color):

- python code
    
    ```python
    import cv2
    import matplotlib.pyplot as plt
    
    img = cv2.imread('images/drawing.png')
    rows,cols,ch = img.shape
    
    pts1 = np.float32([[38,38],[145,38],[38,145]])   
    pts2 = np.float32([[10,100],[200,50],[100,250]])
    
    M = cv2.getAffineTransform(pts1,pts2)
    
    dst = cv2.warpAffine(img,M,(cols,rows))
    
    plt.subplot(121),plt.imshow(img),plt.title('Input'),plt.axis('off')
    plt.subplot(122),plt.imshow(dst),plt.title('Output'),plt.axis('off')
    plt.show()
    ```
    
- result
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0f7af6bd-709c-4bde-889a-0317112b5880/Untitled.png)
    

### The example for the Affine Transformation

`OpenCv`ì˜ mouse callback functionì„ ì´ìš©í•œ ì˜ˆì œì„.

- python code
    
    ```python
    import cv2
    import numpy as np
    
    points = []
    
    # ì™¼ìª½ ìƒë‹¨, ì˜¤ë¥¸ìª½ ìƒë‹¨, ì™¼ìª½ í•˜ë‹¨, ì˜¤ë¥¸ìª½ í•˜ë‹¨ ìˆœìœ¼ë¡œ í´ë¦­í•˜ì‹œì˜¤.
    
    # mouse callback function
    def draw_circle(event,x,y,flags,param):
        if event == cv2.EVENT_LBUTTONDBLCLK:
            global points
            cv2.circle(img,(x,y),10,(255,0,0),-1)
            print(x,y)
            points.append([x,y])
            
            
    # Create a black image, a window and bind the function to window
    img = cv2.imread('images/drawing.png')
    rows,cols,ch = img.shape
    cv2.namedWindow('image')
    cv2.setMouseCallback('image',draw_circle)
    
    while(1):
        cv2.imshow('image',img)
        if cv2.waitKey(20) & 0xFF == 27: # enter ESC
            break
        if len(points) == 3:
            pts1 = np.float32(points)
            pts2 = np.float32([[10,100],[200,50],[100,250]])
            M = cv2.getAffineTransform(pts1,pts2)        
            dst = cv2.warpAffine(img,M,(cols,rows))
            cv2.imshow('after',dst)
            
    cv2.destroyAllWindows()
    ```
    

for the details : [Affine Transform](https://www.notion.so/Affine-Transform-ed7b3cb2080d47d3bdd0be0569b6b78b) 

# PerspectiveÂ Transformation

ForÂ perspectiveÂ transformation,Â youÂ needÂ aÂ $3\times3$Â transformationÂ matrix.

$$
\begin{bmatrix}Â w\hat{x}Â \\Â w\hat{y}Â \\Â wÂ \end{bmatrix}
=
\begin{bmatrix}
aÂ &Â bÂ &Â cÂ \\
dÂ &Â eÂ &Â fÂ \\
gÂ &Â hÂ &Â 1
\end{bmatrix}
\begin{bmatrix}
xÂ \\Â yÂ \\Â 1
\end{bmatrix}
$$

**StraightÂ linesÂ willÂ remainÂ straight**Â evenÂ afterÂ theÂ transformation.

- Perspective(ì›ê·¼ë²•)Â ë³€í™˜ì€Â ì„ ì˜Â ì„±ì§ˆë§ŒÂ ìœ ì§€(***ì§ì„ ***ì€Â ë³€í™˜Â í›„ì—ë„Â ***ì§ì„ ***)
- ë‹¨,Â ì„ ì˜Â í‰í–‰ì„±ì€Â ìœ ì§€ê°€Â ë˜ì§€Â ì•ŠìŒ

ToÂ findÂ **PerspectiveÂ TransformationÂ Matrix**,Â weÂ needÂ **4Â points**Â onÂ theÂ inputÂ imageÂ andÂ correspondingÂ pointsÂ onÂ theÂ outputÂ image.

- AmongÂ theseÂ 4Â points,Â **3Â ofÂ themÂ shouldÂ *notÂ beÂ colinear***.

ThenÂ transformationÂ matrixÂ canÂ beÂ foundÂ byÂ theÂ functionÂ `cv2.getPerspectiveTransform`.

- 8Â variablesÂ canÂ beÂ obtainedÂ byÂ followingÂ matrixÂ equation.
- 8Â variablesÂ =Â 8Â DegreeÂ ofÂ FreedomÂ (8DoF)
    
    $$
    \begin{bmatrix}Â \hat{x}_1Â \\Â \hat{y}_1Â \\Â \hat{x}_2Â \\Â \hat{y}_2Â \\Â \hat{x}_3Â \\Â \hat{y}_3Â \\Â \hat{x}_4Â \\Â \hat{y}_4Â \end{bmatrix}
    =
    \begin{bmatrix}
    x_1Â &Â y_1Â &Â 1Â &Â 0Â &Â 0Â &Â 0Â &Â -x_1\hat{x}_1Â &Â -\hat{x}_1y_1Â \\
    0Â &Â 0Â &Â 0Â &Â x_1Â &Â y_1Â &Â 1Â &Â -x_1\hat{y}_1Â &Â -y_1\hat{y}_1Â \\
    x_2Â &Â y_2Â &Â 1Â &Â 0Â &Â 0Â &Â 0Â &Â -x_2\hat{x}_2Â &Â -\hat{x}_2y_2Â \\
    0Â &Â 0Â &Â 0Â &Â x_2Â &Â y_2Â &Â 1Â &Â -x_2\hat{y}_2Â &Â -y_2\hat{y}_2Â \\
    x_3Â &Â y_3Â &Â 1Â &Â 0Â &Â 0Â &Â 0Â &Â -x_3\hat{x}_3Â &Â -\hat{x}_3y_3Â \\
    0Â &Â 0Â &Â 0Â &Â x_3Â &Â y_3Â &Â 1Â &Â -x_3\hat{y}_3Â &Â -y_3\hat{y}_3Â \\
    x_4Â &Â y_4Â &Â 1Â &Â 0Â &Â 0Â &Â 0Â &Â -x_4\hat{x}_4Â &Â -\hat{x}_4y_4Â \\
    0Â &Â 0Â &Â 0Â &Â x_4Â &Â y_4Â &Â 1Â &Â -x_4\hat{y}_4Â &Â -y_4\hat{y}_4
    \end{bmatrix}
    \begin{bmatrix}
    aÂ \\Â bÂ \\Â cÂ \\Â dÂ \\Â eÂ \\Â fÂ \\Â gÂ \\Â h
    \end{bmatrix}
    $$
    

ThenÂ applyÂ `cv2.warpPerspective`Â withÂ thisÂ $3\times3$Â transformationÂ matrix.

SeeÂ theÂ codeÂ below:

- python code
    
    ```python
    import cv2
    import numpy as np
    from matplotlib import pyplot as plt
    
    img = cv2.imread('images/Railroad-Tracks-Perspective.jpg')
    # [x,y] ì¢Œí‘œì ì„ 4x2ì˜ í–‰ë ¬ë¡œ ì‘ì„±
    # ì¢Œí‘œì ì€ ì¢Œìƒ->ì¢Œí•˜->ìš°ìƒ->ìš°í•˜
    pts1 = np.float32([[504,1003],[243,1525],[1000,1000],[1280,1685]])
    
    # ì¢Œí‘œì˜ ì´ë™ì 
    pts2 = np.float32([[10,10],[10,1000],[1000,10],[1000,1000]])
    
    # pts1ì˜ ì¢Œí‘œì— í‘œì‹œ. perspective ë³€í™˜ í›„ ì´ë™ ì  í™•ì¸.
    cv2.circle(img, (504,1003), 20, (255,0,0),-1)
    cv2.circle(img, (243,1524), 20, (0,255,0),-1)
    cv2.circle(img, (1000,1000), 20, (0,0,255),-1)
    cv2.circle(img, (1280,1685), 20, (0,0,0),-1)
    
    M = cv2.getPerspectiveTransform(pts1, pts2)
    print(type(M))
    print(M)
    
    dst = cv2.warpPerspective(img, M, (1100,1100))
    
    plt.subplot(121),plt.imshow(img),plt.title('image')
    plt.subplot(122),plt.imshow(dst),plt.title('Perspective')
    plt.show()
    ```
    
- result
    
    <class 'numpy.ndarray'>
    [[-2.02153837e+00 -1.02691611e+00  2.04001743e+03]
     [-2.24880859e-02 -3.30149532e+00  3.31389904e+03]
     [-2.62496544e-04 -1.74594051e-03  1.00000000e+00]]
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fa452dbf-f3ce-4052-b676-783f73a999c6/Untitled.png)
    
- python code 2
    
    ```python
    img = cv2.imread('images/sudokusmall.png')
    rows,cols,ch = img.shape
    
    pts1 = np.float32([[62,69],[392,54],[31,404],[413,410]])
    pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
    
    M = cv2.getPerspectiveTransform(pts1,pts2)
    
    dst = cv2.warpPerspective(img,M,(300,300))
    
    plt.subplot(121),plt.imshow(img),plt.title('Input')
    plt.xticks([]);plt.yticks([])
    plt.subplot(122),plt.imshow(dst),plt.title('Output')
    plt.xticks([]);plt.yticks([])
    plt.show()
    ```
    
- result 2
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3f0130f5-fe32-46dc-b6cd-9973fd1ce2fc/Untitled.png)
    

### The example for the Perspective Transformation

OpenCvì˜ mouse callback functionì„ ì´ìš©í•œ ì˜ˆì œì„.

```python
import cv2
import numpy as np

points = []

# ì™¼ìª½ ìƒë‹¨, ì˜¤ë¥¸ìª½ ìƒë‹¨, ì™¼ìª½ í•˜ë‹¨, ì˜¤ë¥¸ìª½ í•˜ë‹¨ ìˆœìœ¼ë¡œ í´ë¦­í•˜ì‹œì˜¤.

# mouse callback function
def draw_circle(event,x,y,flags,param):
    if event == cv2.EVENT_LBUTTONDBLCLK:
        global points
        cv2.circle(img,(x,y),10,(255,0,0),-1)
        print(x,y)
        points.append([x,y])
        
        
# Create a black image, a window and bind the function to window
img = cv2.imread('images/sudoku.jpg')
cv2.namedWindow('image')
cv2.setMouseCallback('image',draw_circle)

while(1):
    cv2.imshow('image',img)
    if cv2.waitKey(20) & 0xFF == 27: # enter ESC
        break
    if len(points) == 4:
        pts1 = np.float32(points)
        pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])
        M = cv2.getPerspectiveTransform(pts1,pts2)        
        dst = cv2.warpPerspective(img,M,(300,300))
        cv2.imshow('after',dst)
        
cv2.destroyAllWindows()
```

# Rotation in 3D using OpenCV's `warpPerspective`

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9e83dc06-d156-4362-a7c1-0ec5c766df9b/Untitled.png)

- python code
    
    ```python
    from skimage import data
    from skimage import img_as_ubyte,img_as_float
    import cv2
    import numpy as np
    import matplotlib.pyplot as plt
    '''
    input: the image that you want rotated.
    output: the Mat object to put the resulting file in.
    alpha: the rotation around the x axis
    beta: the rotation around the y axis
    gamma: the rotation around the z axis (basically a 2D rotation)
    dx: translation along the x axis
    dy: translation along the y axis
    dz: translation along the z axis (distance between lens and the object) (commonly use 200)
    f: focal distance (distance between lens and image, a smaller number exaggerates the effect)
    
    Author : Michael Jepson 
    Original src : C++ 
    Original src's URL : http://jepsonsblog.blogspot.com/2012/11/rotation-in-3d-using-opencvs.html
    '''
    def rotateImage(input, alpha, beta, gamma, dx, dy, dz, f):
        #alpha = (alpha - 90.)*np.pi/180.;
        #beta = (beta - 90.)*np.pi/180.;
        #gamma = (gamma - 90.)*np.pi/180.;
        alpha = (alpha)*np.pi/180.;
        beta = (beta)*np.pi/180.;
        gamma = (gamma)*np.pi/180.;
        
        
        # get width and height for ease of use in matrices
        h,w = input.shape[:2]
        print('height:',h,'width:',w)
        
        # Projection 2D -> 3D matrix
        A1 = np.array([
            [1,0,-w/2.],
            [0,1,-h/2.],
            [0,0,0],
            [0,0,1]])
        
        # Rotation matrices around the X, Y, and Z axis
        RX = np.array([
            [1,0,0,0],
            [0,np.cos(alpha),-np.sin(alpha),0],
            [0,np.sin(alpha), np.cos(alpha),0],
            [0,0,0,1]])
        
        RY = np.array([
            [np.cos(beta),0,-np.sin(beta),0],
            [0           ,1,            0,0],
            [np.sin(beta),0, np.cos(beta),0],
            [0,0,0,1]])
        
        RZ = np.array([
            [np.cos(gamma),-np.sin(gamma),0,0],        
            [np.sin(gamma), np.cos(gamma),0,0],
            [0           ,0,            1,0],
            [0,0,0,1]])
        
        # Composed rotation matrix with (RX, RY, RZ)
        R = np.dot(RZ,np.dot(RY,RX))
        R2 = RZ@RY@RX
        if not(np.array_equal(R2,R)):
            print(R2-R)
        
        # Translation matrix
        T = np.array([
            [1,0,0,dx],        
            [0,1,0,dy],
            [0,0,1,dz],
            [0,0,0,1]])
        
        A2 = np.array([
            [f,0,w/2.,0],        
            [0,f,h/2.,0],        
            [0,0,1,0]])
        
        # Final transformation matrix       
        M2 = np.dot(A2,np.dot(T,np.dot(R,A1)))
        M = A2 @ (T @ (R @ A1))
        if not(np.array_equal(M2,M)):
            print(M2-M)
        print(M)
        
        
        
        dst = cv2.warpPerspective(img,M,(w,h))
        return dst
    
    cat = data.chelsea() # take the test image of cat!
    
    img = cv2.cvtColor(cat, cv2.COLOR_RGB2GRAY)
    #img = cv2.imread('cat_cv.tif',0)
    h,w = img.shape[:2]
    
    dst = rotateImage(img,0,0,0,0,0,50,100)
        
    plt.figure(figsize=(20,10))    
    plt.subplot(121),plt.imshow(img),plt.title('Input')
    plt.xticks([]);plt.yticks([])
    plt.subplot(122),plt.imshow(dst),plt.title('Output')
    plt.xticks([]);plt.yticks([])
    plt.show()
    ```
    

# References

[[ì˜ìƒ Geometry #3] 2D ë³€í™˜ (Transformations)](https://darkpgmr.tistory.com/79?category=460965)

[[ì˜ìƒì²˜ë¦¬] ì¼ì§€ 16: Transformations -- ê¸°ë³¸ì ì´ë©° ì „ë°˜ì  ì´í•´ë¥¼ ìœ„í•´](https://blog.daum.net/shksjy/228)

[Homography - Wikipedia](https://en.wikipedia.org/wiki/Homography)

[ì´ë¯¸ì§€ Geometric Transformation ì•Œì•„ë³´ê¸°](https://gaussian37.github.io/vision-concept-geometric_transformation/)

[opencv-python ì½”ë“œ snippets](https://gaussian37.github.io/vision-opencv_python_snippets/#warpaffine%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EA%B8%B0%ED%95%98%ED%95%99%EC%A0%81-%EB%B3%80%ED%99%98-1)

[Image Geometric Transformation In Numpy and OpenCV](https://towardsdatascience.com/image-geometric-transformation-in-numpy-and-opencv-936f5cd1d315)
